# Core Concepts for Institutional Data Science & AI

## Data Pipeline

- Short definition: A sequence of steps that collects, cleans, transforms, and delivers data for analysis or model use.
- Why it matters in UN/IATA/CERN context: Institutional programs rely on consistent, traceable data flows across teams, systems, and reporting cycles.

## Reproducibility

- Short definition: The ability to rerun the same workflow and obtain the same result using the same data, code, and settings.
- Why it matters in UN/IATA/CERN context: High-stakes operations and scientific work require repeatable evidence for audits, peer review, and policy decisions.

## Cross Validation

- Short definition: A method for testing model performance by training and validating on multiple data splits.
- Why it matters in UN/IATA/CERN context: It reduces overconfidence and gives stronger evidence that results generalize across regions, routes, or experiments.

## Overfitting

- Short definition: When a model learns noise or quirks in training data and performs poorly on new data.
- Why it matters in UN/IATA/CERN context: Overfit models can create unsafe or misleading recommendations in operational or scientific settings.

## Class Imbalance

- Short definition: A dataset condition where one outcome class is much more common than another.
- Why it matters in UN/IATA/CERN context: Rare but important events (incidents, anomalies, failures) may be missed unless imbalance is handled carefully.

## Anomaly Detection

- Short definition: Techniques used to identify unusual patterns that differ from normal behavior.
- Why it matters in UN/IATA/CERN context: Early detection of irregular events can support safety monitoring, humanitarian logistics, and instrument health checks.

## Distributed Computing

- Short definition: Running computation across multiple machines or processes to handle larger workloads faster.
- Why it matters in UN/IATA/CERN context: Large-scale datasets and simulations often exceed single-machine capacity and require coordinated processing.

## Explainability

- Short definition: The ability to describe why a model produced a specific output in understandable terms.
- Why it matters in UN/IATA/CERN context: Analysts, auditors, and decision-makers need interpretable evidence before trusting automated outputs.

## Model Drift

- Short definition: Performance decline caused by changes in data patterns, behavior, or operating conditions over time.
- Why it matters in UN/IATA/CERN context: Environments change; monitoring drift prevents silent degradation in mission-critical systems.

## Governance

- Short definition: The policies, roles, and controls that guide how data and AI systems are developed and used.
- Why it matters in UN/IATA/CERN context: Clear governance supports accountability, compliance, and cross-organizational coordination.

## Auditability

- Short definition: The ability to inspect and verify data, code, decisions, and model outputs after the fact.
- Why it matters in UN/IATA/CERN context: External review, compliance checks, and scientific validation depend on complete traceable records.
